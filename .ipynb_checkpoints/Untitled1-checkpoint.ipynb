{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'word2vec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a2a562fab18f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'word2vec'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import collections\n",
    "import seaborn as sns\n",
    "import word2vec\n",
    "\n",
    "trainrecipts = json.load(open('recipies.json','r'))\n",
    "\n",
    "# Quick&dirty code to extract info2list\n",
    "raw_ingredients = list()\n",
    "\n",
    "for recipt in trainrecipts:\n",
    "    for ingredient in recipt[u'ingredients']:\n",
    "        raw_ingredients.append(ingredient.strip())\n",
    "        \n",
    "\n",
    "raw_cuisines = list()\n",
    "for recipt in trainrecipts:\n",
    "    raw_cuisines.append(recipt[u'cuisine'].strip())\n",
    "\n",
    "# use Counter to get frequencies \n",
    "counts_ingr = collections.Counter(raw_ingredients)\n",
    "counts_cuis = collections.Counter(raw_cuisines)\n",
    "\n",
    "# this will help us to have an idea how our corpora of \n",
    "# ingredients looks like\n",
    "print('Size Ingredients dataset (with repetition):  \\t{}'.format((len(raw_ingredients))))\n",
    "print('Unique Ingredients dataset: \\t\\t\\t{}'.format((len(counts_ingr.values()))))\n",
    "\n",
    "# This will provide a distribution of cusines, indirect \n",
    "# info of the ingredients\n",
    "print('Total # of recipts \\t\\t\\t\\t{}'.format(len(raw_cuisines)))\n",
    "print('Total # of Cuisines \\t\\t\\t\\t{}'.format((len(counts_cuis.values()))))\n",
    "\n",
    "# top 10\n",
    "counts_cuis.most_common(10)\n",
    "\n",
    "# lets plot this \n",
    "# sort\n",
    "x_cu = [cu for cu, frq in counts_cuis.most_common()]\n",
    "y_frq = [frq for cu, frq in counts_cuis.most_common()]\n",
    "fbar = sns.barplot(x = x_cu, y = y_frq)\n",
    "# xlabels\n",
    "for item in fbar.get_xticklabels():\n",
    "    item.set_rotation(90)\n",
    "\n",
    "# init a dict with a empty list\n",
    "num_ingredients = dict(zip(counts_cuis.keys(), [list() for x in counts_cuis.keys()]))\n",
    "for recipt in trainrecipts:\n",
    "    # append the number in the list\n",
    "    num_ingredients[recipt['cuisine']].append(len(recipt['ingredients']))\n",
    "\n",
    "len(num_ingredients)\n",
    "\n",
    "for cu, frq in num_ingredients.items():\n",
    "\n",
    "    print('{}    \\t\\t{:.2f}'.format(cu, np.mean(frq)))\n",
    "\n",
    "x_cu = [cu for cu, frq in num_ingredients.items()]\n",
    "y_frq = [np.mean(frq) for cu, frq in num_ingredients.items()]\n",
    "err = [np.std(frq) for cu, frq in num_ingredients.items()]\n",
    "fbar = sns.barplot(x = x_cu, y = y_frq, yerr=err)\n",
    "# xlabels\n",
    "for item in fbar.get_xticklabels():\n",
    "    item.set_rotation(90)\n",
    "\n",
    "# Dispersion of the frequencies Ingredients\n",
    "print(np.mean(list(counts_ingr.values())))\n",
    "print(np.std(list(counts_ingr.values())))\n",
    "\n",
    "# top 15\n",
    "counts_ingr.most_common(15)\n",
    "\n",
    "# Tail 50\n",
    "counts_ingr.most_common()[-50:]\n",
    "\n",
    "symbols = list()\n",
    "\n",
    "for recipt in trainrecipts:\n",
    "\n",
    "    # I want ingredient remove \n",
    "    for ingredient in recipt['ingredients']:\n",
    "        if re.match(\"\\(|@|\\$\\?\", ingredient.lower()):\n",
    "            symbols.append(ingredient)\n",
    "len(symbols)\n",
    "counts_symbols = collections.Counter(symbols)\n",
    "counts_symbols.most_common(20)\n",
    "\n",
    "sentences = list()\n",
    "# one hot ingredients\n",
    "\n",
    "\n",
    "for recipt in trainrecipts:\n",
    "    clean_recipt = list()\n",
    "    # I want ingredient remove \n",
    "    for ingredient in recipt['ingredients']:\n",
    "        # remove this description from the ingredients\n",
    "        # minimal preprocessing\n",
    "        ingredient =  re.sub(r'\\(.*oz.\\)|crushed|crumbles|ground|minced|powder|chopped|sliced',\n",
    "                             '', \n",
    "                             ingredient)\n",
    "        clean_recipt.append(ingredient.strip())\n",
    "    sentences.append(clean_recipt)\n",
    "        \n",
    "len(sentences)\n",
    "\n",
    "# Set values for NN parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 3    # 50% of the corpus                    \n",
    "num_workers = 4       # Number of CPUs\n",
    "context = 10          # Context window size; \n",
    "                      # let's use avg recipte size                                                                                  \n",
    "downsampling = 1e-3   # threshold for configuring which \n",
    "                    # higher-frequency words are randomly downsampled\n",
    "\n",
    "# Initialize and train the model \n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:theano_p36]",
   "language": "python",
   "name": "conda-env-theano_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
